{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas I - Data Structures\n",
    "\n",
    "\n",
    "**Pandas** is a Python package providing fast, flexible, and expressive data structures designed to make working with \"relational\" or \"labeled\" data both easy and intuitive. It aims to be the fundamental high-level building block for\n",
    "doing practical, **real world** data analysis in Python. Additionally, it has the broader goal of becoming **the most powerful and flexible open source data analysis / manipulation tool available in any language**. It is already well on\n",
    "its way toward this goal.\n",
    "\n",
    "Here are some of pandas main features:\n",
    "\n",
    "- Easy handling of [missing data][missing-data] (represented as `NaN`) in floating point as well as non-floating point data\n",
    "- Size mutability: columns can be [inserted and deleted][insertion-deletion] from DataFrame and higher dimensional objects\n",
    "- Automatic and explicit [data alignment][alignment]: objects can be explicitly aligned to a set of labels, or the user can simply ignore the labels and let `Series`, `DataFrame`, etc. automatically align the data for you in computations\n",
    "- Powerful, flexible [group by][groupby] functionality to perform split-apply-combine operations on data sets, for both aggregating and transforming data\n",
    "- Make it [easy to convert][conversion] ragged, differently-indexed data in other Python and NumPy data structures into DataFrame objects\n",
    "- Intelligent label-based [slicing][slicing], [fancy indexing][fancy-indexing], and [subsetting][subsetting] of large data sets\n",
    "- Intuitive [merging][merging] and [joining][joining] data sets\n",
    "- Flexible [reshaping][reshape] and [pivoting][pivot-table] of data sets\n",
    "- [Hierarchical][mi] labeling of axes (possible to have multiple labels per tick)\n",
    "- Robust I/O tools for loading data from [flat files][flat-files] (CSV and delimited), [Excel files][excel], [databases][db], and saving/loading data from the ultrafast [HDF5 format][hdfstore]\n",
    "- [Time series][timeseries]-specific functionality: date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging, etc.\n",
    "\n",
    "[missing-data]: http://pandas.pydata.org/pandas-docs/stable/missing_data.html#working-with-missing-data\n",
    "[insertion-deletion]: http://pandas.pydata.org/pandas-docs/stable/dsintro.html#column-selection-addition-deletion\n",
    "[alignment]: http://pandas.pydata.org/pandas-docs/stable/dsintro.html?highlight=alignment#intro-to-data-structures\n",
    "[groupby]: http://pandas.pydata.org/pandas-docs/stable/groupby.html#group-by-split-apply-combine\n",
    "[conversion]: http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\n",
    "[slicing]: http://pandas.pydata.org/pandas-docs/stable/indexing.html#slicing-ranges\n",
    "[fancy-indexing]: http://pandas.pydata.org/pandas-docs/stable/indexing.html#advanced-indexing-with-ix\n",
    "[subsetting]: http://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing\n",
    "[merging]: http://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging\n",
    "[joining]: http://pandas.pydata.org/pandas-docs/stable/merging.html#joining-on-index\n",
    "[reshape]: http://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-and-pivot-tables\n",
    "[pivot-table]: http://pandas.pydata.org/pandas-docs/stable/reshaping.html#pivot-tables-and-cross-tabulations\n",
    "[mi]: http://pandas.pydata.org/pandas-docs/stable/indexing.html#hierarchical-indexing-multiindex\n",
    "[flat-files]: http://pandas.pydata.org/pandas-docs/stable/io.html#csv-text-files\n",
    "[excel]: http://pandas.pydata.org/pandas-docs/stable/io.html#excel-files\n",
    "[db]: http://pandas.pydata.org/pandas-docs/stable/io.html#sql-queries\n",
    "[hdfstore]: http://pandas.pydata.org/pandas-docs/stable/io.html#hdf5-pytables\n",
    "[timeseries]: http://pandas.pydata.org/pandas-docs/stable/timeseries.html#time-series-date-functionality\n",
    "\n",
    "To dive deeper into the package, check out [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrames and Series**<br>\n",
    "Pandas introduces two new data structures to Python - [Series](http://pandas.pydata.org/pandas-docs/dev/dsintro.html#series) and [DataFrame](http://pandas.pydata.org/pandas-docs/dev/dsintro.html#dataframe), both of which are built on top of [NumPy](http://www.numpy.org/) (this means it's fast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the necessary CSV files [here](https://github.com/gjreda/gregreda.com/tree/master/content/notebooks/data) and the MovieLens dataset [here](http://files.grouplens.org/datasets/movielens/ml-100k.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. [Series](#1.-Series)<br>\n",
    "    1.1 Creating<br>\n",
    "    1.2 Selecting<br>\n",
    "    1.3 Editing<br>\n",
    "    1.3 Mathematical Operations<br>\n",
    "    1.3 Missing Values\n",
    "2. [DataFrames](#2.-DataFrames)<br>\n",
    "    2.1 From Dictionnary of Lists<br>\n",
    "    2.2 From/To CSV<br>\n",
    "    2.3 From/To Excel<br>\n",
    "    2.4 From/To Database<br>\n",
    "    2.5 From Clipboard<br>\n",
    "    2.6 From URL<br>\n",
    "    2.7 From Google Analytics API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Series is a one-dimensional object similar to an array, list, or column in a table. It will assign a labeled index to each item in the Series. By default, each item will receive an index label from 0 to N, where N is the length of the Series minus one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                7\n",
       "1       Heisenberg\n",
       "2             3.14\n",
       "3      -1789710578\n",
       "4    Happy Eating!\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a Series with an arbitrary list\n",
    "s = pd.Series([7, 'Heisenberg', 3.14, -1789710578, 'Happy Eating!'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can specify an index to use when creating the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A                7\n",
       "Z       Heisenberg\n",
       "C             3.14\n",
       "Y      -1789710578\n",
       "E    Happy Eating!\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([7, 'Heisenberg', 3.14, -1789710578, 'Happy Eating!'],\n",
    "              index=['A', 'Z', 'C', 'Y', 'E'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Series constructor can convert a dictonary as well, using the keys of the dictionary as its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Austin            450\n",
       "Boston            NaN\n",
       "Chicago          1000\n",
       "New York         1300\n",
       "Portland          900\n",
       "San Francisco    1100\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Chicago': 1000, 'New York': 1300, 'Portland': 900, 'San Francisco': 1100,\n",
    "     'Austin': 450, 'Boston': None}\n",
    "cities = pd.Series(d)\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Selecting\n",
    "\n",
    "You can use the index to select specific items from the Series ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities['Chicago']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chicago          1000\n",
       "Portland          900\n",
       "San Francisco    1100\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities[['Chicago', 'Portland', 'San Francisco']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can use boolean indexing for selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Austin      450\n",
       "Portland    900\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities[cities < 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That last one might be a little weird, so let's make it more clear - `cities < 1000` returns a Series of True/False values, which we then pass to our Series `cities`, returning the corresponding True items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austin            True\n",
      "Boston           False\n",
      "Chicago          False\n",
      "New York         False\n",
      "Portland          True\n",
      "San Francisco    False\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "Austin      450\n",
      "Portland    900\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "less_than_1000 = cities < 1000\n",
    "print less_than_1000\n",
    "print '\\n'\n",
    "print cities[less_than_1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Editing\n",
    "\n",
    "You can also change the values in a Series on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old value: 1000.0\n",
      "New value: 1400.0\n"
     ]
    }
   ],
   "source": [
    "# changing based on the index\n",
    "print 'Old value:', cities['Chicago']\n",
    "cities['Chicago'] = 1400\n",
    "print 'New value:', cities['Chicago']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austin      450\n",
      "Portland    900\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Austin      750\n",
      "Portland    750\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# changing values using boolean logic\n",
    "print cities[cities < 1000]\n",
    "print '\\n'\n",
    "cities[cities < 1000] = 750\n",
    "\n",
    "print cities[cities < 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Mathematical Operations\n",
    "Mathematical operations can be done using scalars and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Austin           250.000000\n",
       "Boston                  NaN\n",
       "Chicago          466.666667\n",
       "New York         433.333333\n",
       "Portland         250.000000\n",
       "San Francisco    366.666667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide city values by 3\n",
    "cities / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Austin            562500\n",
       "Boston               NaN\n",
       "Chicago          1960000\n",
       "New York         1690000\n",
       "Portland          562500\n",
       "San Francisco    1210000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# square city values\n",
    "np.square(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add two Series together, which returns a union of the two Series with the addition occurring on the shared index values.  Values on either Series that did not have a shared index will produce a NULL/NaN (not a number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago     1400\n",
      "New York    1300\n",
      "Portland     750\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Austin       750\n",
      "New York    1300\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Austin       NaN\n",
      "Chicago      NaN\n",
      "New York    2600\n",
      "Portland     NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print cities[['Chicago', 'New York', 'Portland']]\n",
    "print'\\n'\n",
    "print cities[['Austin', 'New York']]\n",
    "print'\\n'\n",
    "print cities[['Chicago', 'New York', 'Portland']] + cities[['Austin', 'New York']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that because Austin, Chicago, and Portland were not found in both Series, they were returned with NULL/NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Missing Values\n",
    "\n",
    "What if you aren't sure whether an item is in the Series?  You can check using idiomatic Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print 'Seattle' in cities\n",
    "print 'San Francisco' in cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NULL checking can be performed with `isnull` and `notnull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Austin            True\n",
       "Boston           False\n",
       "Chicago           True\n",
       "New York          True\n",
       "Portland          True\n",
       "San Francisco     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a boolean series indicating which values aren't NULL\n",
    "cities.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austin           False\n",
      "Boston            True\n",
      "Chicago          False\n",
      "New York         False\n",
      "Portland         False\n",
      "San Francisco    False\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "Boston   NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# use boolean logic to grab the NULL cities\n",
    "print cities.isnull()\n",
    "print '\\n'\n",
    "print cities[cities.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DataFrames\n",
    "\n",
    "A DataFrame is a tablular data structure comprised of rows and columns, akin to a spreadsheet, database table, or R's data.frame object. You can also think of a DataFrame as a group of Series objects that share an index (the column names)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 From Dictionnary of Lists\n",
    "\n",
    "To create a DataFrame out of common Python data structures, we can pass a **dictionary of lists** to the DataFrame constructor.\n",
    "Using the `columns` parameter allows us to tell the constructor how we'd like the columns ordered. By default, the DataFrame constructor will order the columns alphabetically (though this isn't the case when reading from a file - more on that next)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year     team  wins  losses\n",
      "0  2010    Bears    11       5\n",
      "1  2011    Bears     8       8\n",
      "2  2012    Bears    10       6\n",
      "3  2011  Packers    15       1\n",
      "4  2012  Packers    11       5\n",
      "5  2010    Lions     6      10\n",
      "6  2011    Lions    10       6\n",
      "7  2012    Lions     4      12\n"
     ]
    }
   ],
   "source": [
    "data = {'year': [2010, 2011, 2012, 2011, 2012, 2010, 2011, 2012],\n",
    "        'team': ['Bears', 'Bears', 'Bears', 'Packers', 'Packers', 'Lions', 'Lions', 'Lions'],\n",
    "        'wins': [11, 8, 10, 15, 11, 6, 10, 4],\n",
    "        'losses': [5, 8, 6, 1, 5, 10, 6, 12]}\n",
    "football = pd.DataFrame(data, columns=['year', 'team', 'wins', 'losses'])\n",
    "print football"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much more often, you'll have a dataset you want to read into a DataFrame. Let's go through several common ways of doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 From/To CSV\n",
    "\n",
    "Reading a CSV is as simple as calling the **`read_csv()`** function. By default, the `read_csv()` function expects the column separator to be a comma, but you can change that using the `sep` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/romainlepert/Dropbox/tutorials/pandas/'\n",
      "/Users/romainlepert/Programming/Jupyter/notebooks/Pandas library\n"
     ]
    }
   ],
   "source": [
    "%cd ~/Dropbox/tutorials/pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: mariano-rivera.csv: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# Source: baseball-reference.com/players/r/riverma01.shtml\n",
    "!head -n 5 data/mariano-rivera.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Lg</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W-L%</th>\n",
       "      <th>ERA</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>GF</th>\n",
       "      <th>CG</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SV</th>\n",
       "      <th>IP</th>\n",
       "      <th>H</th>\n",
       "      <th>R</th>\n",
       "      <th>ER</th>\n",
       "      <th>HR</th>\n",
       "      <th>BB</th>\n",
       "      <th>IBB</th>\n",
       "      <th>SO</th>\n",
       "      <th>HBP</th>\n",
       "      <th>BK</th>\n",
       "      <th>WP</th>\n",
       "      <th>BF</th>\n",
       "      <th>ERA+</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>H/9</th>\n",
       "      <th>HR/9</th>\n",
       "      <th>BB/9</th>\n",
       "      <th>SO/9</th>\n",
       "      <th>SO/BB</th>\n",
       "      <th>Awards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>25</td>\n",
       "      <td>NYY</td>\n",
       "      <td>AL</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625</td>\n",
       "      <td>5.51</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>71</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>84</td>\n",
       "      <td>1.507</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996</td>\n",
       "      <td>26</td>\n",
       "      <td>NYY</td>\n",
       "      <td>AL</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.727</td>\n",
       "      <td>2.09</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>107.2</td>\n",
       "      <td>73</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>425</td>\n",
       "      <td>240</td>\n",
       "      <td>0.994</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3.82</td>\n",
       "      <td>CYA-3MVP-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997</td>\n",
       "      <td>27</td>\n",
       "      <td>NYY</td>\n",
       "      <td>AL</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.88</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>71.2</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>301</td>\n",
       "      <td>239</td>\n",
       "      <td>1.186</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.40</td>\n",
       "      <td>ASMVP-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>28</td>\n",
       "      <td>NYY</td>\n",
       "      <td>AL</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.91</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>61.1</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>233</td>\n",
       "      <td>1.060</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>29</td>\n",
       "      <td>NYY</td>\n",
       "      <td>AL</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571</td>\n",
       "      <td>1.83</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>69.0</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>268</td>\n",
       "      <td>257</td>\n",
       "      <td>0.884</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.89</td>\n",
       "      <td>ASCYA-3MVP-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Age   Tm  Lg  W  L   W-L%   ERA   G  GS  GF  CG  SHO  SV     IP   H  \\\n",
       "0  1995   25  NYY  AL  5  3  0.625  5.51  19  10   2   0    0   0   67.0  71   \n",
       "1  1996   26  NYY  AL  8  3  0.727  2.09  61   0  14   0    0   5  107.2  73   \n",
       "2  1997   27  NYY  AL  6  4  0.600  1.88  66   0  56   0    0  43   71.2  65   \n",
       "3  1998   28  NYY  AL  3  0  1.000  1.91  54   0  49   0    0  36   61.1  48   \n",
       "4  1999   29  NYY  AL  4  3  0.571  1.83  66   0  63   0    0  45   69.0  43   \n",
       "\n",
       "    R  ER  HR  BB  IBB   SO  HBP  BK  WP   BF  ERA+   WHIP  H/9  HR/9  BB/9  \\\n",
       "0  43  41  11  30    0   51    2   1   0  301    84  1.507  9.5   1.5   4.0   \n",
       "1  25  25   1  34    3  130    2   0   1  425   240  0.994  6.1   0.1   2.8   \n",
       "2  17  15   5  20    6   68    0   0   2  301   239  1.186  8.2   0.6   2.5   \n",
       "3  13  13   3  17    1   36    1   0   0  246   233  1.060  7.0   0.4   2.5   \n",
       "4  15  14   2  18    3   52    3   1   2  268   257  0.884  5.6   0.3   2.3   \n",
       "\n",
       "   SO/9  SO/BB         Awards  \n",
       "0   6.9   1.70            NaN  \n",
       "1  10.9   3.82    CYA-3MVP-12  \n",
       "2   8.5   3.40       ASMVP-25  \n",
       "3   5.3   2.12            NaN  \n",
       "4   6.8   2.89  ASCYA-3MVP-14  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_csv = pd.read_csv('data/mariano-rivera.csv')\n",
    "from_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our file had headers, which the function inferred upon reading in the file. Had we wanted to be more explicit, we could have passed `header=None` to the function along with a list of column names to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,2012-09-09,DEN,,PIT,W 31-19,3,71,Demaryius Thomas,Trail 7-13,Lead 14-13*\r\n",
      "2,1,2012-09-09,DEN,,PIT,W 31-19,4,1,Jacob Tamme,Trail 14-19,Lead 22-19*\r\n",
      "3,2,2012-09-17,DEN,@,ATL,L 21-27,2,17,Demaryius Thomas,Trail 0-20,Trail 7-20\r\n",
      "4,3,2012-09-23,DEN,,HOU,L 25-31,4,38,Brandon Stokley,Trail 11-31,Trail 18-31\r\n",
      "5,3,2012-09-23,DEN,,HOU,L 25-31,4,6,Joel Dreessen,Trail 18-31,Trail 25-31\r\n"
     ]
    }
   ],
   "source": [
    "# command line : read head of file\n",
    "# Source: pro-football-reference.com/players/M/MannPe00/touchdowns/passing/2012/\n",
    "!head -n 5 data/peyton-passing-TDs-2012.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>game</th>\n",
       "      <th>date</th>\n",
       "      <th>team</th>\n",
       "      <th>home_away</th>\n",
       "      <th>opponent</th>\n",
       "      <th>result</th>\n",
       "      <th>quarter</th>\n",
       "      <th>distance</th>\n",
       "      <th>receiver</th>\n",
       "      <th>score_before</th>\n",
       "      <th>score_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-09</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PIT</td>\n",
       "      <td>W 31-19</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>Demaryius Thomas</td>\n",
       "      <td>Trail 7-13</td>\n",
       "      <td>Lead 14-13*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-09</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PIT</td>\n",
       "      <td>W 31-19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Jacob Tamme</td>\n",
       "      <td>Trail 14-19</td>\n",
       "      <td>Lead 22-19*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-09-17</td>\n",
       "      <td>DEN</td>\n",
       "      <td>@</td>\n",
       "      <td>ATL</td>\n",
       "      <td>L 21-27</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Demaryius Thomas</td>\n",
       "      <td>Trail 0-20</td>\n",
       "      <td>Trail 7-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOU</td>\n",
       "      <td>L 25-31</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>Brandon Stokley</td>\n",
       "      <td>Trail 11-31</td>\n",
       "      <td>Trail 18-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-09-23</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOU</td>\n",
       "      <td>L 25-31</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Joel Dreessen</td>\n",
       "      <td>Trail 18-31</td>\n",
       "      <td>Trail 25-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num  game        date team home_away opponent   result  quarter  distance  \\\n",
       "0    1     1  2012-09-09  DEN       NaN      PIT  W 31-19        3        71   \n",
       "1    2     1  2012-09-09  DEN       NaN      PIT  W 31-19        4         1   \n",
       "2    3     2  2012-09-17  DEN         @      ATL  L 21-27        2        17   \n",
       "3    4     3  2012-09-23  DEN       NaN      HOU  L 25-31        4        38   \n",
       "4    5     3  2012-09-23  DEN       NaN      HOU  L 25-31        4         6   \n",
       "\n",
       "           receiver score_before  score_after  \n",
       "0  Demaryius Thomas   Trail 7-13  Lead 14-13*  \n",
       "1       Jacob Tamme  Trail 14-19  Lead 22-19*  \n",
       "2  Demaryius Thomas   Trail 0-20   Trail 7-20  \n",
       "3   Brandon Stokley  Trail 11-31  Trail 18-31  \n",
       "4     Joel Dreessen  Trail 18-31  Trail 25-31  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['num', 'game', 'date', 'team', 'home_away', 'opponent',\n",
    "        'result', 'quarter', 'distance', 'receiver', 'score_before',\n",
    "        'score_after']\n",
    "no_headers = pd.read_csv('data/peyton-passing-TDs-2012.csv', sep=',', header=None,\n",
    "                         names=cols)\n",
    "no_headers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas various *reader* functions have many parameters allowing you to do things like skipping lines of the file, parsing dates, or specifying how to handle NA/NULL datapoints.\n",
    "\n",
    "**Writing to CSV**\n",
    "\n",
    "There's also a set of *writer* functions for writing to a variety of formats (CSVs, HTML tables, JSON).  They function exactly as you'd expect and are typically called `to_format`:\n",
    "\n",
    "```python\n",
    "my_dataframe.to_csv('path_to_file.csv')\n",
    "```\n",
    "\n",
    "[Take a look at the IO documentation](http://pandas.pydata.org/pandas-docs/stable/io.html) to familiarize yourself with file reading/writing functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 From/To Excel\n",
    "\n",
    "Know who hates [VBA](http://en.wikipedia.org/wiki/Visual_Basic_for_Applications)? Me. I bet you do, too. Thankfully, pandas allows you to read and write Excel files, so you can easily read from Excel, write your code in Python, and then write back out to Excel - no need for VBA.\n",
    "\n",
    "Reading Excel files requires the [xlrd](https://pypi.python.org/pypi/xlrd) library. You can install it via [pip](http://www.pip-installer.org/en/latest/) (*pip install xlrd*).\n",
    "\n",
    "Let's first write a DataFrame to Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year     team  wins  losses\n",
      "0  2010    Bears    11       5\n",
      "1  2011    Bears     8       8\n",
      "2  2012    Bears    10       6\n",
      "3  2011  Packers    15       1\n",
      "4  2012  Packers    11       5\n"
     ]
    }
   ],
   "source": [
    "# this is the DataFrame we created from a dictionary earlier\n",
    "print football.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# since our index on the football DataFrame is meaningless, let's not write it\n",
    "football.to_excel('data/football.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 romainlepert  staff  5589 17 sep 20:50 data/football.xlsx\r\n"
     ]
    }
   ],
   "source": [
    "# command line : list .xlsx files\n",
    "!ls -l data/*.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete the DataFrame\n",
    "del football"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year     team  wins  losses\n",
      "0  2010    Bears    11       5\n",
      "1  2011    Bears     8       8\n",
      "2  2012    Bears    10       6\n",
      "3  2011  Packers    15       1\n",
      "4  2012  Packers    11       5\n",
      "5  2010    Lions     6      10\n",
      "6  2011    Lions    10       6\n",
      "7  2012    Lions     4      12\n"
     ]
    }
   ],
   "source": [
    "# read from Excel\n",
    "football = pd.read_excel('data/football.xlsx')\n",
    "print football"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 From/To Database\n",
    "\n",
    "pandas also has some support for reading/writing DataFrames directly from/to a database [[docs](http://pandas.pydata.org/pandas-docs/stable/io.html#sql-queries)].  You'll typically just need to pass a connection object to the `read_frame` or `write_frame` functions within the `pandas.io` module.\n",
    "\n",
    "Note that `write_frame` executes as a series of INSERT INTO statements and thus trades speed for simplicity. If you're writing a large DataFrame to a database, it might be quicker to write the DataFrame to CSV and load that directly using the database's file import arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-cecd5634d8e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/greda/Dropbox/gregreda.com/_code/towed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SELECT * FROM towed WHERE make = 'FORD';\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "from pandas.io import sql\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('/Users/greda/Dropbox/gregreda.com/_code/towed')\n",
    "query = \"SELECT * FROM towed WHERE make = 'FORD';\"\n",
    "\n",
    "results = sql.read_frame(query, con=conn)\n",
    "print results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 From Clipboard\n",
    "\n",
    "While the results of a query can be read directly into a DataFrame, I prefer to read the results directly from the clipboard. I'm often tweaking queries in my SQL client ([Sequel Pro](http://www.sequelpro.com/)), so I would rather see the results *before* I read it into pandas. Once I'm confident I have the data I want, then I'll read it into a DataFrame.\n",
    "\n",
    "This works just as well with any type of delimited data you've copied to your clipboard. The function does a good job of inferring the delimiter, but you can also use the `sep` parameter to be explicit.\n",
    "\n",
    "[Hank Aaron](http://www.baseball-reference.com/players/a/aaronha01.shtml)\n",
    "\n",
    "![hank-aaron-stats-screenshot](http://i.imgur.com/xiySJ2e.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hank = pd.read_clipboard()\n",
    "hank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 From URL\n",
    "\n",
    "We can also use the Python's [StringIO](http://docs.python.org/2/library/stringio.html) library to read data directly from a URL. StringIO allows you to treat a string as a file-like object.\n",
    "\n",
    "Let's use the [best sandwiches data](https://raw.github.com/gjreda/best-sandwiches/master/data/best-sandwiches-geocode.tsv) that I [wrote about scraping](http://www.gregreda.com/2013/05/06/more-web-scraping-with-python/) a while back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>sandwich</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>full_address</th>\n",
       "      <th>formatted_address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BLT</td>\n",
       "      <td>Old Oak Tap</td>\n",
       "      <td>The B is applewood smoked&amp;mdash;nice and snapp...</td>\n",
       "      <td>$10</td>\n",
       "      <td>2109 W. Chicago Ave.</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>773-772-0406</td>\n",
       "      <td>theoldoaktap.com</td>\n",
       "      <td>2109 W. Chicago Ave., Chicago</td>\n",
       "      <td>2109 West Chicago Avenue, Chicago, IL 60622, USA</td>\n",
       "      <td>41.895734</td>\n",
       "      <td>-87.679960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fried Bologna</td>\n",
       "      <td>Au Cheval</td>\n",
       "      <td>Thought your bologna-eating days had retired w...</td>\n",
       "      <td>$9</td>\n",
       "      <td>800 W. Randolph St.</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>312-929-4580</td>\n",
       "      <td>aucheval.tumblr.com</td>\n",
       "      <td>800 W. Randolph St., Chicago</td>\n",
       "      <td>800 West Randolph Street, Chicago, IL 60607, USA</td>\n",
       "      <td>41.884672</td>\n",
       "      <td>-87.647754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Woodland Mushroom</td>\n",
       "      <td>Xoco</td>\n",
       "      <td>Leave it to Rick Bayless and crew to come up w...</td>\n",
       "      <td>$9.50.</td>\n",
       "      <td>445 N. Clark St.</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>312-334-3688</td>\n",
       "      <td>rickbayless.com</td>\n",
       "      <td>445 N. Clark St., Chicago</td>\n",
       "      <td>445 North Clark Street, Chicago, IL 60654, USA</td>\n",
       "      <td>41.890602</td>\n",
       "      <td>-87.630925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank           sandwich   restaurant  \\\n",
       "0     1                BLT  Old Oak Tap   \n",
       "1     2      Fried Bologna    Au Cheval   \n",
       "2     3  Woodland Mushroom         Xoco   \n",
       "\n",
       "                                         description   price  \\\n",
       "0  The B is applewood smoked&mdash;nice and snapp...     $10   \n",
       "1  Thought your bologna-eating days had retired w...      $9   \n",
       "2  Leave it to Rick Bayless and crew to come up w...  $9.50.   \n",
       "\n",
       "                address     city         phone              website  \\\n",
       "0  2109 W. Chicago Ave.  Chicago  773-772-0406     theoldoaktap.com   \n",
       "1   800 W. Randolph St.  Chicago  312-929-4580  aucheval.tumblr.com   \n",
       "2      445 N. Clark St.  Chicago  312-334-3688      rickbayless.com   \n",
       "\n",
       "                    full_address  \\\n",
       "0  2109 W. Chicago Ave., Chicago   \n",
       "1   800 W. Randolph St., Chicago   \n",
       "2      445 N. Clark St., Chicago   \n",
       "\n",
       "                                  formatted_address        lat        lng  \n",
       "0  2109 West Chicago Avenue, Chicago, IL 60622, USA  41.895734 -87.679960  \n",
       "1  800 West Randolph Street, Chicago, IL 60607, USA  41.884672 -87.647754  \n",
       "2    445 North Clark Street, Chicago, IL 60654, USA  41.890602 -87.630925  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib2 import urlopen\n",
    "from StringIO import StringIO\n",
    "\n",
    "# store the text from the URL response in our url variable\n",
    "url = urlopen('https://raw.github.com/gjreda/best-sandwiches/master/data/best-sandwiches-geocode.tsv').read()\n",
    "\n",
    "# treat the tab-separated text as a file with StringIO and read it into a DataFrame\n",
    "from_url = pd.read_table(StringIO(url), sep='\\t')\n",
    "from_url.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 From Google Analytics API\n",
    "\n",
    "pandas also has some integration with the Google Analytics API, though there is some setup required. I won't be covering it, but you can read more about it [here](http://blog.yhathq.com/posts/pandas-google-analytics.html) and [here](http://quantabee.wordpress.com/2012/12/17/google-analytics-pandas/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
